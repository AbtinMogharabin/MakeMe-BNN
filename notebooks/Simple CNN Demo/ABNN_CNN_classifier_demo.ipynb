{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AoXdUp79d8CL",
        "AL7gMgK93UqT",
        "cS3UXMDZwmM4",
        "OhKKLx5JAnzq",
        "3LIQtXOFIWUd",
        "IpQxUPVV6VPH",
        "YAas1qBvIovm",
        "IPppy_FS52vd",
        "HYV-mZuBIqJa",
        "f8W_F8G-IzbY",
        "to_mOzrTI2VV",
        "FpQrqv19I5gC",
        "DsCg3LDgI9zK",
        "BV9SutwYJAKV",
        "e-67WomZ21Ua"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An implementation of Adaptive Bayesian Neural Networks (ABNN) for a basic CNN image classifier on CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "jBXHs2m0APxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries and datasets"
      ],
      "metadata": {
        "id": "NW9xd8Xc3UqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "HN4DP_qhYRw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netcal\n",
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvc77o82xGwt",
        "outputId": "65a3f97c-b622-4349-d203-56aaba6eaf99",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:01:23.202404Z",
          "iopub.execute_input": "2024-06-05T14:01:23.202860Z",
          "iopub.status.idle": "2024-06-05T14:02:03.705305Z",
          "shell.execute_reply.started": "2024-06-05T14:01:23.202827Z",
          "shell.execute_reply": "2024-06-05T14:02:03.703607Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netcal in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from netcal) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from netcal) (1.11.4)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from netcal) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from netcal) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from netcal) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from netcal) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.40 in /usr/local/lib/python3.10/dist-packages (from netcal) (4.66.4)\n",
            "Requirement already satisfied: pyro-ppl>=1.8 in /usr/local/lib/python3.10/dist-packages (from netcal) (1.9.1)\n",
            "Requirement already satisfied: tikzplotlib==0.9.8 in /usr/local/lib/python3.10/dist-packages (from netcal) (0.9.8)\n",
            "Requirement already satisfied: tensorboard>=2.2 in /usr/local/lib/python3.10/dist-packages (from netcal) (2.15.2)\n",
            "Requirement already satisfied: gpytorch>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from netcal) (1.11)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tikzplotlib==0.9.8->netcal) (9.4.0)\n",
            "Requirement already satisfied: linear-operator>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from gpytorch>=1.5.1->netcal) (0.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->netcal) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->netcal) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->netcal) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->netcal) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->netcal) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->netcal) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->netcal) (2.8.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8->netcal) (3.3.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8->netcal) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->netcal) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->netcal) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2->netcal) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->netcal) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->netcal) (12.5.40)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2->netcal) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2->netcal) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2->netcal) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.2->netcal) (1.3.1)\n",
            "Requirement already satisfied: jaxtyping>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch>=1.5.1->netcal) (0.2.29)\n",
            "Requirement already satisfied: typeguard~=2.13.3 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch>=1.5.1->netcal) (2.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->netcal) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->netcal) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->netcal) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->netcal) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2->netcal) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->netcal) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2->netcal) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.2->netcal) (3.2.2)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from torch.nn.functional import softmax\n",
        "import torch.nn.functional as F\n",
        "import netcal.metrics as metrics\n",
        "from netcal.metrics import ECE\n",
        "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score, roc_curve\n",
        "\n",
        "# Import ABNN's essential components\n",
        "# from ABNN import BNL, CustomMAPLoss, replace_normalization_layers\n",
        "# from ABNN_Metrics import (\n",
        "#         calculate_accuracy, calculate_uncertainty, calculate_nll, calculate_ece,\n",
        "#         calculate_aupr, calculate_auc, calculate_fpr95, count_parameters,\n",
        "#         predict_with_uncertainty, plot_uncertainty\n",
        "#     )\n",
        "\n",
        "# Import the base CNN model\n",
        "# from Simple_CNN import Net\n",
        "\n",
        "# Set the start method to 'spawn'\n",
        "import multiprocessing\n",
        "multiprocessing.set_start_method('spawn', force=True)"
      ],
      "metadata": {
        "id": "REotBNCV3UqO",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:12:00.811304Z",
          "iopub.execute_input": "2024-06-05T14:12:00.812037Z",
          "iopub.status.idle": "2024-06-05T14:12:08.293364Z",
          "shell.execute_reply.started": "2024-06-05T14:12:00.811988Z",
          "shell.execute_reply": "2024-06-05T14:12:08.291682Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Augment CIFAR-10"
      ],
      "metadata": {
        "id": "XFwNb7Gf3UqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the paper, I only use Horizontal Flip for data augmentation"
      ],
      "metadata": {
        "id": "uyQVyB3oCizi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSmx1nli3UqS",
        "outputId": "03925d5f-5517-4e1b-8d79-2f9b31cdbcdb",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:12:08.295965Z",
          "iopub.execute_input": "2024-06-05T14:12:08.296692Z",
          "iopub.status.idle": "2024-06-05T14:12:17.057845Z",
          "shell.execute_reply.started": "2024-06-05T14:12:08.296655Z",
          "shell.execute_reply": "2024-06-05T14:12:17.056226Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Train the base model and save the weights"
      ],
      "metadata": {
        "id": "AoXdUp79d8CL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the base CNN model"
      ],
      "metadata": {
        "id": "AL7gMgK93UqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Conv layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)  # Using BatchNorm here for conv layer\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.in2 = nn.InstanceNorm2d(64, affine=True)  # Using InstanceNorm here for conv layer\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.ln3 = nn.LayerNorm([128, 8, 8])  # Using LayerNorm here for conv layer\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.ln4 = nn.LayerNorm(256)  # Using LayerNorm here for fc layer\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.bn5 = nn.BatchNorm1d(128)  # Using BatchNorm here for fc layer\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.in2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.ln3(self.conv3(x))))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.ln4(self.fc1(x)))\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "a4UNu1Ei4qr4",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:12:17.059760Z",
          "iopub.execute_input": "2024-06-05T14:12:17.060219Z",
          "iopub.status.idle": "2024-06-05T14:12:17.075224Z",
          "shell.execute_reply.started": "2024-06-05T14:12:17.060182Z",
          "shell.execute_reply": "2024-06-05T14:12:17.073546Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net = Net()\n",
        "net.to(device)  # Move the model to GPU if available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6tINOK8I2rE",
        "outputId": "f87214c7-6f76-45df-e6dd-63d4890e80e2",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:12:17.078913Z",
          "iopub.execute_input": "2024-06-05T14:12:17.079374Z",
          "iopub.status.idle": "2024-06-05T14:12:17.169651Z",
          "shell.execute_reply.started": "2024-06-05T14:12:17.079341Z",
          "shell.execute_reply": "2024-06-05T14:12:17.168135Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (in2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (ln3): LayerNorm((128, 8, 8), eps=1e-05, elementwise_affine=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
              "  (ln4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (bn5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the summary of the model\n",
        "summary(net, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C0LFYpR44gh",
        "outputId": "7891e7b3-8f35-4ee6-eca6-1d4dc8c202d2",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:12:17.171226Z",
          "iopub.execute_input": "2024-06-05T14:12:17.171701Z",
          "iopub.status.idle": "2024-06-05T14:12:17.342576Z",
          "shell.execute_reply.started": "2024-06-05T14:12:17.171652Z",
          "shell.execute_reply": "2024-06-05T14:12:17.340989Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
            "            Conv2d-4           [-1, 64, 16, 16]          18,496\n",
            "    InstanceNorm2d-5           [-1, 64, 16, 16]             128\n",
            "         MaxPool2d-6             [-1, 64, 8, 8]               0\n",
            "            Conv2d-7            [-1, 128, 8, 8]          73,856\n",
            "         LayerNorm-8            [-1, 128, 8, 8]          16,384\n",
            "         MaxPool2d-9            [-1, 128, 4, 4]               0\n",
            "           Linear-10                  [-1, 256]         524,544\n",
            "        LayerNorm-11                  [-1, 256]             512\n",
            "           Linear-12                  [-1, 128]          32,896\n",
            "      BatchNorm1d-13                  [-1, 128]             256\n",
            "           Linear-14                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 669,322\n",
            "Trainable params: 669,322\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.99\n",
            "Params size (MB): 2.55\n",
            "Estimated Total Size (MB): 3.56\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the base CNN model"
      ],
      "metadata": {
        "id": "cS3UXMDZwmM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the training of our base model, I use standard image classification methods: standard cross-entropy loss and SGD"
      ],
      "metadata": {
        "id": "zvc2_IXbDuNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "5kIIN6kx3UqW",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:12:17.344530Z",
          "iopub.execute_input": "2024-06-05T14:12:17.345000Z",
          "iopub.status.idle": "2024-06-05T14:12:17.355404Z",
          "shell.execute_reply.started": "2024-06-05T14:12:17.344965Z",
          "shell.execute_reply": "2024-06-05T14:12:17.353617Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "# Training\n",
        "train_losses = []\n",
        "\n",
        "# Training\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Move inputs and labels to GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    print(f'[epoch {epoch + 1}, loss: {running_loss / 3000:.6f}')\n",
        "    running_loss = 0\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Time taken to train the model: {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc-ZwEfR-Jvb",
        "outputId": "e900ae65-5b0d-4150-fedb-69e7e3cd5ed2",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:12:17.357664Z",
          "iopub.execute_input": "2024-06-05T14:12:17.358066Z",
          "iopub.status.idle": "2024-06-05T14:28:29.416447Z",
          "shell.execute_reply.started": "2024-06-05T14:12:17.358037Z",
          "shell.execute_reply": "2024-06-05T14:28:29.414627Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 1, loss: 0.154708\n",
            "[epoch 2, loss: 0.107863\n",
            "[epoch 3, loss: 0.092632\n",
            "[epoch 4, loss: 0.082888\n",
            "[epoch 5, loss: 0.075239\n",
            "[epoch 6, loss: 0.069646\n",
            "[epoch 7, loss: 0.064024\n",
            "[epoch 8, loss: 0.060947\n",
            "[epoch 9, loss: 0.056376\n",
            "[epoch 10, loss: 0.053229\n",
            "[epoch 11, loss: 0.049484\n",
            "[epoch 12, loss: 0.046479\n",
            "[epoch 13, loss: 0.043952\n",
            "[epoch 14, loss: 0.041753\n",
            "[epoch 15, loss: 0.038616\n",
            "[epoch 16, loss: 0.037123\n",
            "[epoch 17, loss: 0.035332\n",
            "[epoch 18, loss: 0.033494\n",
            "[epoch 19, loss: 0.031514\n",
            "[epoch 20, loss: 0.030402\n",
            "Finished Training\n",
            "Time taken to train the model: 512.33 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training loss\n",
        "plt.figure()\n",
        "plt.plot(train_losses)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "HY9IXUXCKigX",
        "outputId": "01d25151-7832-4a1a-d57f-b4043c40ad5a",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:28:29.419059Z",
          "iopub.execute_input": "2024-06-05T14:28:29.419596Z",
          "iopub.status.idle": "2024-06-05T14:28:29.798169Z",
          "shell.execute_reply.started": "2024-06-05T14:28:29.419560Z",
          "shell.execute_reply": "2024-06-05T14:28:29.796387Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and save the model's weights"
      ],
      "metadata": {
        "id": "OhKKLx5JAnzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QNSWKlOuYi3",
        "outputId": "12e73a3c-1c1d-46d6-bd97-716dc779033d",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:28:29.800120Z",
          "iopub.execute_input": "2024-06-05T14:28:29.800597Z",
          "iopub.status.idle": "2024-06-05T14:28:48.395370Z",
          "shell.execute_reply.started": "2024-06-05T14:28:29.800564Z",
          "shell.execute_reply": "2024-06-05T14:28:48.393895Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 79.00 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model weights\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "print('Saved the model weights')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlwO4roL3gqN",
        "outputId": "75f45156-d385-4960-a634-cc0f9a0562fd",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:28:48.399730Z",
          "iopub.execute_input": "2024-06-05T14:28:48.400990Z",
          "iopub.status.idle": "2024-06-05T14:28:48.417351Z",
          "shell.execute_reply.started": "2024-06-05T14:28:48.400944Z",
          "shell.execute_reply": "2024-06-05T14:28:48.415717Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved the model weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the ABNN version"
      ],
      "metadata": {
        "id": "6S-mVSFzeH0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BNL old versions"
      ],
      "metadata": {
        "id": "3LIQtXOFIWUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BNL(nn.Module):\n",
        "    \"\"\"\n",
        "    Bayesian Normalization Layer (BNL).\n",
        "\n",
        "    This layer replaces traditional normalization including like BatchNorm,\n",
        "    LayerNorm, and InstanceNorm. It adapts normalization to account for Bayesian\n",
        "    inference, making the model more robust to variations and uncertainties in\n",
        "    the data.\n",
        "\n",
        "    BNL adds gaussian noise during both inference and trainig stages.\n",
        "\n",
        "    Args:\n",
        "        num_features (int): The number of features in the input.\n",
        "\n",
        "    Methods:\n",
        "        forward(x): Applies Bayesian normalization to the input tensor.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features):\n",
        "        super(BNL, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.gamma_4d = nn.Parameter(torch.ones(1, num_features, 1, 1))\n",
        "        self.beta_4d = nn.Parameter(torch.zeros(1, num_features, 1, 1))\n",
        "        self.gamma_2d = nn.Parameter(torch.ones(1, num_features))\n",
        "        self.beta_2d = nn.Parameter(torch.zeros(1, num_features))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 4:  # 4D Input: Used for mini-batch of images. The four dimensions are [batch size, channels, height, width]\n",
        "            batch_mean = torch.mean(x, dim=(0, 2, 3), keepdim=True)\n",
        "            batch_var = torch.var(x, dim=(0, 2, 3), keepdim=True)\n",
        "            noise = torch.randn(x.shape[0], self.num_features, 1, 1).to(x.device)\n",
        "            x = (x - batch_mean) / torch.sqrt(batch_var + self.eps)\n",
        "            x = x * (self.gamma_4d * (1 + noise)) + self.beta_4d\n",
        "        elif x.dim() == 2:  # 2D Input: common for in fully connected layers. The two dimensions are [batch size, features]\n",
        "            batch_mean = torch.mean(x, dim=0, keepdim=True)\n",
        "            batch_var = torch.var(x, dim=0, keepdim=True)\n",
        "            noise = torch.randn(x.shape[0], self.num_features).to(x.device)\n",
        "            x = (x - batch_mean) / torch.sqrt(batch_var + self.eps)\n",
        "            x = x * (self.gamma_2d * (1 + noise)) + self.beta_2d\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported input dimensions: {x.dim()}\")\n",
        "        return x"
      ],
      "metadata": {
        "id": "tLHAxAgSIZ1P",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:45:06.015402Z",
          "iopub.execute_input": "2024-06-05T14:45:06.015886Z",
          "iopub.status.idle": "2024-06-05T14:45:06.032740Z",
          "shell.execute_reply.started": "2024-06-05T14:45:06.015852Z",
          "shell.execute_reply": "2024-06-05T14:45:06.030889Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BNL(nn.Module):\n",
        "    def __init__(self, num_features, epsilon_std=1.0):\n",
        "        super(BNL, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.epsilon_std = epsilon_std\n",
        "\n",
        "        # Learnable parameters\n",
        "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
        "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "        # Running statistics\n",
        "        self.running_mean = torch.zeros(num_features)\n",
        "        self.running_var = torch.ones(num_features)\n",
        "\n",
        "        # Initialize the random noise\n",
        "        self.epsilon = torch.randn(num_features) * self.epsilon_std\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device  # Get the device of the input tensor\n",
        "\n",
        "        # Ensure running statistics are on the same device\n",
        "        self.running_mean = self.running_mean.to(device)\n",
        "        self.running_var = self.running_var.to(device)\n",
        "        self.gamma = self.gamma.to(device)\n",
        "        self.beta = self.beta.to(device)\n",
        "        self.epsilon = self.epsilon.to(device)\n",
        "\n",
        "        if self.training:\n",
        "            batch_mean = torch.mean(x, dim=[0, 2, 3])\n",
        "            batch_var = torch.var(x, dim=[0, 2, 3], unbiased=False)\n",
        "\n",
        "            # Update running statistics\n",
        "            self.running_mean = 0.9 * self.running_mean + 0.1 * batch_mean\n",
        "            self.running_var = 0.9 * self.running_var + 0.1 * batch_var\n",
        "        else:\n",
        "            batch_mean = self.running_mean\n",
        "            batch_var = self.running_var\n",
        "\n",
        "        # Add Gaussian noise to gamma\n",
        "        if self.training:\n",
        "            self.epsilon = torch.randn(self.num_features, device=device) * self.epsilon_std\n",
        "        gamma_noisy = self.gamma * (1 + self.epsilon)\n",
        "\n",
        "        # Normalize the input\n",
        "        x_normalized = (x - batch_mean[None, :, None, None]) / torch.sqrt(batch_var[None, :, None, None] + 1e-5)\n",
        "\n",
        "        return gamma_noisy[None, :, None, None] * x_normalized + self.beta[None, :, None, None]"
      ],
      "metadata": {
        "id": "ywSbDVrg9yEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BNL(nn.Module):\n",
        "    def __init__(self, num_features, epsilon_std=1.0):\n",
        "        super(BNL, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.epsilon_std = epsilon_std\n",
        "\n",
        "        # Learnable parameters\n",
        "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
        "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "        # Running statistics\n",
        "        self.running_mean = torch.zeros(num_features)\n",
        "        self.running_var = torch.ones(num_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        self.running_mean = self.running_mean.to(device)\n",
        "        self.running_var = self.running_var.to(device)\n",
        "        self.gamma = self.gamma.to(device)\n",
        "        self.beta = self.beta.to(device)\n",
        "\n",
        "        if x.dim() == 4:  # Input from conv layers\n",
        "            if self.training:\n",
        "                batch_mean = x.mean([0, 2, 3], keepdim=True)\n",
        "                batch_var = x.var([0, 2, 3], keepdim=True, unbiased=False)\n",
        "                self.running_mean = 0.9 * self.running_mean + 0.1 * batch_mean.squeeze()\n",
        "                self.running_var = 0.9 * self.running_var + 0.1 * batch_var.squeeze()\n",
        "            else:\n",
        "                batch_mean = self.running_mean.view(1, -1, 1, 1)\n",
        "                batch_var = self.running_var.view(1, -1, 1, 1)\n",
        "        elif x.dim() == 2:  # Input from fully connected layers\n",
        "            if self.training:\n",
        "                batch_mean = x.mean(0, keepdim=True)\n",
        "                batch_var = x.var(0, keepdim=True, unbiased=False)\n",
        "                self.running_mean = 0.9 * self.running_mean + 0.1 * batch_mean.squeeze()\n",
        "                self.running_var = 0.9 * self.running_var + 0.1 * batch_var.squeeze()\n",
        "            else:\n",
        "                batch_mean = self.running_mean.view(1, -1)\n",
        "                batch_var = self.running_var.view(1, -1)\n",
        "\n",
        "        if self.training:\n",
        "            self.epsilon = torch.randn(self.num_features, device=device) * self.epsilon_std\n",
        "        else:\n",
        "            self.epsilon = torch.zeros(self.num_features, device=device)\n",
        "\n",
        "        gamma_noisy = self.gamma * (1 + self.epsilon)\n",
        "\n",
        "        # Normalize the input\n",
        "        x_normalized = (x - batch_mean) / torch.sqrt(batch_var + 1e-5)\n",
        "\n",
        "        # Adjust gamma and beta for broadcasting\n",
        "        if x.dim() == 4:\n",
        "            gamma_noisy = gamma_noisy.view(1, -1, 1, 1)\n",
        "            beta = self.beta.view(1, -1, 1, 1)\n",
        "        elif x.dim() == 2:\n",
        "            gamma_noisy = gamma_noisy.view(1, -1)\n",
        "            beta = self.beta.view(1, -1)\n",
        "\n",
        "        return gamma_noisy * x_normalized + beta\n"
      ],
      "metadata": {
        "id": "MeCC96nh-RT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BNL and ABNN loss current version"
      ],
      "metadata": {
        "id": "PoPygvmL9P9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class BNL(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Bayesian Normalization Layer (BNL) that can directly replace traditional\n",
        "#     normalization layers like BatchNorm, enabling easier weight transfer from models\n",
        "#     using BatchNorm.\n",
        "\n",
        "#     This implementation includes parameters named `weight` and `bias` to directly\n",
        "#     match those used in PyTorch's BatchNorm layers for compatibility when loading\n",
        "#     state dictionaries.\n",
        "\n",
        "#     Args:\n",
        "#         num_features (int): Number of features in the input, matches channels in conv\n",
        "#                             layers or features in linear layers.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, num_features):\n",
        "#         super(BNL, self).__init__()\n",
        "#         self.num_features = num_features\n",
        "#         self.weight = nn.Parameter(torch.ones(num_features))\n",
        "#         self.bias = nn.Parameter(torch.zeros(num_features))\n",
        "#         self.eps = 1e-5\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         mean = x.mean([0, 2, 3], keepdim=True) if x.dim() == 4 else x.mean(0, keepdim=True)\n",
        "#         var = x.var([0, 2, 3], keepdim=True) if x.dim() == 4 else x.var(0, keepdim=True)\n",
        "#         x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "#         # Gaussian noise applied to the weights\n",
        "#         noise = torch.randn(self.weight.shape, device=x.device)\n",
        "#         gamma_noisy = self.weight * (1 + noise)\n",
        "\n",
        "#         if x.dim() == 4:\n",
        "#             gamma_noisy = gamma_noisy.view(1, -1, 1, 1)\n",
        "#             bias = self.bias.view(1, -1, 1, 1)\n",
        "#         elif x.dim() == 2:\n",
        "#             gamma_noisy = gamma_noisy.view(1, -1)\n",
        "#             bias = self.bias.view(1, -1)\n",
        "\n",
        "#         return gamma_noisy * x_normalized + bias\n",
        "\n",
        "\n",
        "# class BNL_layer(nn.Module):  # for special case of layer normalization tha takes a list input\n",
        "#     def __init__(self, num_features):\n",
        "#         super(BNL_layer, self).__init__()\n",
        "#         if isinstance(num_features, int):\n",
        "#             num_features = (num_features,)\n",
        "#         elif isinstance(num_features, list):\n",
        "#             num_features = tuple(num_features)\n",
        "\n",
        "#         self.num_features = num_features\n",
        "#         self.weight = nn.Parameter(torch.ones(num_features))\n",
        "#         self.bias = nn.Parameter(torch.zeros(num_features))\n",
        "#         self.eps = 1e-5\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         mean = x.mean(dim=tuple(range(x.dim())[1:]), keepdim=True)\n",
        "#         var = x.var(dim=tuple(range(x.dim())[1:]), keepdim=True, unbiased=False)\n",
        "#         x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "#         noise = torch.randn(self.weight.shape, device=x.device)\n",
        "#         gamma_noisy = self.weight * (1 + noise)\n",
        "\n",
        "#         weight = self.weight.view((1,) + self.num_features + (1,) * (x.dim() - len(self.num_features) - 1))\n",
        "#         bias = self.bias.view((1,) + self.num_features + (1,) * (x.dim() - len(self.num_features) - 1))\n",
        "\n",
        "#         return gamma_noisy * x_normalized + bias"
      ],
      "metadata": {
        "id": "u6Vj89tWtqQl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BNL(nn.Module):\n",
        "    \"\"\"\n",
        "        Bayesian Normalization Layer (BNL).\n",
        "\n",
        "    This layer replaces traditional normalization layers like BatchNorm,\n",
        "    LayerNorm, and InstanceNorm. It adapts normalization to account for Bayesian\n",
        "    inference, making the model more robust to variations and uncertainties in\n",
        "    the data.\n",
        "\n",
        "    BNL adds gaussian noise during both inference and trainig stages.\n",
        "\n",
        "    This implementation includes parameters named `weight` and `bias` to directly\n",
        "    match those used in PyTorch's BatchNorm, LayerNorm, and InstanceNorm layers\n",
        "    for compatibility when loading state dictionaries.\n",
        "\n",
        "    Args:\n",
        "        num_features (int, list, tuple): Number of features in the input, matches channels\n",
        "                                         in conv layers or features in linear layers. Can\n",
        "                                         be a single integer or a list/tuple for complex scenarios.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features):\n",
        "        super(BNL, self).__init__()\n",
        "        # Check if num_features is a list or tuple, convert if necessary\n",
        "        if isinstance(num_features, int):\n",
        "            num_features = (num_features,)\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.weight = nn.Parameter(torch.ones(num_features))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(self.num_features) == 1:  # Traditional usage like BatchNorm\n",
        "            mean = x.mean([0, 2, 3], keepdim=True) if x.dim() == 4 else x.mean(0, keepdim=True)\n",
        "            var = x.var([0, 2, 3], keepdim=True) if x.dim() == 4 else x.var(0, keepdim=True)\n",
        "            x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "            noise = torch.randn(self.weight.shape, device=x.device)\n",
        "            gamma_noisy = self.weight * (1 + noise)\n",
        "\n",
        "            if x.dim() == 4:\n",
        "                gamma_noisy = gamma_noisy.view(1, -1, 1, 1)\n",
        "                bias = self.bias.view(1, -1, 1, 1)\n",
        "            elif x.dim() == 2:\n",
        "                gamma_noisy = gamma_noisy.view(1, -1)\n",
        "                bias = self.bias.view(1, -1)\n",
        "\n",
        "            return gamma_noisy * x_normalized + bias\n",
        "        else:  # LayerNorm-like usage\n",
        "            mean = x.mean(dim=tuple(range(x.dim())[1:]), keepdim=True)\n",
        "            var = x.var(dim=tuple(range(x.dim())[1:]), keepdim=True, unbiased=False)\n",
        "            x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "            noise = torch.randn(self.weight.shape, device=x.device)\n",
        "            gamma_noisy = self.weight * (1 + noise)\n",
        "\n",
        "            weight = self.weight.view((1,) + self.num_features + (1,) * (x.dim() - len(self.num_features) - 1))\n",
        "            bias = self.bias.view((1,) + self.num_features + (1,) * (x.dim() - len(self.num_features) - 1))\n",
        "\n",
        "            return gamma_noisy * x_normalized + bias"
      ],
      "metadata": {
        "id": "xR4CKlFH3P4w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ABNNLoss(torch.nn.Module):\n",
        "    def __init__(self, Num_classes, model_parameters, Weight_decay=1e-4):\n",
        "        super(ABNNLoss, self).__init__()\n",
        "        self.model_parameters = model_parameters\n",
        "        self.Weight_decay = Weight_decay\n",
        "        self.eta = nn.Parameter(torch.ones(Num_classes))\n",
        "\n",
        "    def forward(self, outputs, labels):\n",
        "        # Calculate the three loss components\n",
        "        nll_loss = self.negative_log_likelihood(outputs, labels)\n",
        "        log_prior_loss = self.negative_log_prior(self.model_parameters, self.Weight_decay)\n",
        "        custom_ce_loss = self.custom_cross_entropy_loss(outputs, labels, self.eta)\n",
        "\n",
        "        # Sum up all three components to form the ABNN loss\n",
        "        total_loss = nll_loss + log_prior_loss + custom_ce_loss\n",
        "        return total_loss\n",
        "\n",
        "    @staticmethod\n",
        "    def negative_log_likelihood(outputs, labels):\n",
        "        # Negative Log Likelihood (NLL) or MLE Loss:\n",
        "        # NLL = - log P(y_i | x_i, )\n",
        "        return torch.nn.functional.cross_entropy(outputs, labels)\n",
        "\n",
        "    def negative_log_prior(self, model_parameters, Weight_decay=1e-4):\n",
        "        # Negative Log Prior with Gaussian Prior (L2 Regularization):\n",
        "        # log P() =   ^2 where  (weight decay) = (1/2^2)\n",
        "        l2_reg = sum(p.pow(2).sum() for p in model_parameters)\n",
        "        return Weight_decay * l2_reg\n",
        "\n",
        "    def custom_cross_entropy_loss(self, outputs, labels, eta):\n",
        "        # Custom Cross-Entropy Loss:\n",
        "        # E() = - _i log P(y_i | x_i, )\n",
        "        log_probs = torch.nn.functional.log_softmax(outputs, dim=1)\n",
        "        weighted_log_probs = eta[labels] * log_probs.gather(1, labels.unsqueeze(1)).squeeze(1)\n",
        "        return -torch.mean(weighted_log_probs)"
      ],
      "metadata": {
        "id": "x6rdkvC9GbEW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the CNN's ABNN version"
      ],
      "metadata": {
        "id": "a1WXC6ajA2jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ABNNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ABNNNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.bn1 = BNL(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.in2 = BNL(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.ln3 = BNL((128, 8, 8))\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.ln4 = BNL(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.bn5 = BNL(128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.in2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.ln3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.ln4(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lAic0WjdesGj",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:45:07.159172Z",
          "iopub.execute_input": "2024-06-05T14:45:07.159611Z",
          "iopub.status.idle": "2024-06-05T14:45:07.179099Z",
          "shell.execute_reply.started": "2024-06-05T14:45:07.159580Z",
          "shell.execute_reply": "2024-06-05T14:45:07.177752Z"
        },
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "abnnnet = ABNNNet()\n",
        "abnnnet.to(device)\n",
        "\n",
        "# Print the summary of the model\n",
        "summary(abnnnet, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeypozkVhdLg",
        "outputId": "da24cc04-4a30-4b02-ea3e-b7703f7a98bc",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:45:08.265079Z",
          "iopub.execute_input": "2024-06-05T14:45:08.265673Z",
          "iopub.status.idle": "2024-06-05T14:45:08.302640Z",
          "shell.execute_reply.started": "2024-06-05T14:45:08.265631Z",
          "shell.execute_reply": "2024-06-05T14:45:08.300669Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "               BNL-2           [-1, 32, 32, 32]              64\n",
            "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
            "            Conv2d-4           [-1, 64, 16, 16]          18,496\n",
            "               BNL-5           [-1, 64, 16, 16]             128\n",
            "         MaxPool2d-6             [-1, 64, 8, 8]               0\n",
            "            Conv2d-7            [-1, 128, 8, 8]          73,856\n",
            "               BNL-8            [-1, 128, 8, 8]          16,384\n",
            "         MaxPool2d-9            [-1, 128, 4, 4]               0\n",
            "           Linear-10                  [-1, 256]         524,544\n",
            "              BNL-11                  [-1, 256]             512\n",
            "           Linear-12                  [-1, 128]          32,896\n",
            "              BNL-13                  [-1, 128]             256\n",
            "           Linear-14                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 669,322\n",
            "Trainable params: 669,322\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.99\n",
            "Params size (MB): 2.55\n",
            "Estimated Total Size (MB): 3.56\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the new model"
      ],
      "metadata": {
        "id": "5CcSbEhOiTst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = ABNNLoss(10, abnnnet.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, abnnnet.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "V-1Y6JEqH9MW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('./cifar_net.pth')\n",
        "\n",
        "# Filter out the keys related to running statistics that BNL doesn't use\n",
        "filtered_state_dict = {k: v for k, v in state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "\n",
        "# Load the filtered state dictionary\n",
        "abnnnet.load_state_dict(filtered_state_dict, strict=True)\n",
        "print('Model weights loaded.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cItJ18hJH_fa",
        "outputId": "bb5f2234-30c5-4ae7-c4f5-1ce55dbb1c8b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Keys in the state dictionary:\")\n",
        "for key in state_dict.keys():\n",
        "    print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YQATWuG6QUk",
        "outputId": "70a73d5a-12b7-41b1-e1ec-1945b56bfc6e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in the state dictionary:\n",
            "conv1.weight\n",
            "conv1.bias\n",
            "bn1.weight\n",
            "bn1.bias\n",
            "bn1.running_mean\n",
            "bn1.running_var\n",
            "bn1.num_batches_tracked\n",
            "conv2.weight\n",
            "conv2.bias\n",
            "in2.weight\n",
            "in2.bias\n",
            "conv3.weight\n",
            "conv3.bias\n",
            "ln3.weight\n",
            "ln3.bias\n",
            "fc1.weight\n",
            "fc1.bias\n",
            "ln4.weight\n",
            "ln4.bias\n",
            "fc2.weight\n",
            "fc2.bias\n",
            "bn5.weight\n",
            "bn5.bias\n",
            "bn5.running_mean\n",
            "bn5.running_var\n",
            "bn5.num_batches_tracked\n",
            "fc3.weight\n",
            "fc3.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Start Training')\n",
        "\n",
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "# List to store loss values\n",
        "train_losses = []\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        eta = torch.rand(labels.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = abnnnet(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "    print(f'[Epoch {epoch + 1}, Loss: {running_loss}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Time taken to train the model: {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qA9IVGNIBon",
        "outputId": "de4cecce-6593-4f16-f745-04381e8a4b68"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n",
            "[Epoch 1, Loss: 1256.3802634477615\n",
            "[Epoch 2, Loss: 931.4795205593109\n",
            "[Epoch 3, Loss: 853.3990067243576\n",
            "[Epoch 4, Loss: 817.771817445755\n",
            "[Epoch 5, Loss: 793.523169875145\n",
            "[Epoch 6, Loss: 770.1933164596558\n",
            "[Epoch 7, Loss: 755.0068476200104\n",
            "[Epoch 8, Loss: 735.917240023613\n",
            "[Epoch 9, Loss: 725.2883818149567\n",
            "[Epoch 10, Loss: 713.6974112987518\n",
            "[Epoch 11, Loss: 702.5278379917145\n",
            "[Epoch 12, Loss: 693.9569231271744\n",
            "[Epoch 13, Loss: 679.0479393005371\n",
            "[Epoch 14, Loss: 680.1117898225784\n",
            "[Epoch 15, Loss: 665.6557961702347\n",
            "[Epoch 16, Loss: 670.6050525903702\n",
            "[Epoch 17, Loss: 658.3752547502518\n",
            "[Epoch 18, Loss: 657.5034958124161\n",
            "[Epoch 19, Loss: 648.2052940130234\n",
            "[Epoch 20, Loss: 642.9247715473175\n",
            "Finished Training\n",
            "Time taken to train the model: 547.83 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "abnnnet.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = abnnnet(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "3Kb9AruTdewi",
        "execution": {
          "iopub.status.busy": "2024-06-05T15:57:39.589885Z",
          "iopub.execute_input": "2024-06-05T15:57:39.590461Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b371f7e4-7dd4-4a1c-839a-51ad98ca9097"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 78.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Instantiate the custom ABNN loss class\n",
        "# eta = torch.rand(64, device=device)  # Adjust the size of `eta` to match your batch size\n",
        "# criterion = ABNNLoss(weight_decay=5e-4).to(device)\n",
        "# optimizer = optim.SGD(filter(lambda p: p.requires_grad, abnnnet.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "OcojbdwDhcjX",
        "execution": {
          "iopub.status.busy": "2024-06-05T14:45:10.683639Z",
          "iopub.execute_input": "2024-06-05T14:45:10.684585Z",
          "iopub.status.idle": "2024-06-05T14:45:10.690292Z",
          "shell.execute_reply.started": "2024-06-05T14:45:10.684537Z",
          "shell.execute_reply": "2024-06-05T14:45:10.688673Z"
        },
        "trusted": true
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model weights\n",
        "PATH = './cifar_abnnnet.pth'\n",
        "torch.save(abnnnet.state_dict(), PATH)\n",
        "print('Saved the model weights')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUQdPMFI9G08",
        "outputId": "d349ebf2-afef-4042-d454-024e3d322bbb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved the model weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the generated outputs (for colab)"
      ],
      "metadata": {
        "id": "e-67WomZ21Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/cifar_net.pth')\n",
        "# files.download('/content/ABNNNet.py')\n",
        "# files.download('/content/cifar_abnnnet.pth')"
      ],
      "metadata": {
        "id": "WcVxNm_J27z2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}